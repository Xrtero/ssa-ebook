# Chapter 19. Instruction Code Selection
**Dietmar Ebner, Andreas Krall, and Bernhard Scholz**


Instruction code selection is a transformation step in a compiler that translates a machine-independent intermediate code representation into a low-level intermediate representation or into machine code for a specific target architecture. Instead of hand-crafting an instruction selector for each target architecture, generator tools have been developed that generate the instruction code selector based on a specification. The specification describes the machine of the target and how the intermediate instructions are mapped to the machine code. This approach is used in large compiler infrastructures such as GCC or LLVM that target a range of architectures. A possible scenario of a code generator in a compiler is depicted in Fig. 19.1. The Intermediate Representation (IR) of an input program is passed on to an optional lowering phase that breaks down instructions and performs other machine-dependent transformations. Thereafter, the instruction selection performs the mapping to machine code or lowered IR based on the machine description of the target architecture.

One of the widely used techniques in code generation is tree-pattern matching. The unit of translation for tree-pattern matching is expressed as a tree structure that is called a data-flow tree (DFT). The basic idea is to describe the target instruction set using an _ambiguous_ cost-annotated graph grammar. The instruction code selector seeks a cost-minimal _cover_ of the DFT. Each of the selected ruleshas an associated semantic action that is used to emit the corresponding machine instructions, either by constructing a new intermediate representation or by rewriting the DFT bottom-up.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100056385.png)


An example of a DFT along with a set of rules representing valid ARM instructions are shown in Fig. 19.2. Each rule consists of non-terminals (shown in lower case) and terminal symbols (shown in upper case). Non-terminals are used to chain individual rules together. Non-terminal $\mathsf{s}$ denotes a distinguished start symbol for the root node of the DFT. Terminal symbols match the corresponding labels of nodes in the data-flow trees. The terminals of the grammar are VAR, CST, SHL, ADD, and LD. Rules that translate from one non-terminal to another are called _chain rules_, e.g., reg $\leftarrow$ imm, which translates an immediate value to a register. Note that there are multiple possibilities to obtain a cover of the data-flow tree for the example shown in Fig. 19.2b. Each rule has associated costs. The cost of a tree cover is the sum of the costs of the selected rules. For example, the DFT could be covered by rules $R_{3}$, $R_{4}$, and $R_{10}$, which would give a total cost for the cover of one cost unit. Alternatively, the DFT could be covered by rules $R_{2}$, $R_{3}$, $R_{5}$, $R_{7}$, and $R_{8}$ yielding four cost units for the cover for issuing four assembly instructions. A dynamic programming algorithm selects a cost-optimal cover for the DFT.

Tree-pattern matching on a DFT is limited to the scope of tree structures. To overcome this limitation, we can extend the scope of the matching algorithm to the computational flow of a whole procedure. The use of the SSA form as an intermediate representation improves the code generation by making def-use relationships explicit. Hence, SSA exposes the data flow of a translation unit and utilizes the code generation process. Instead of using a textual SSA representation, we employ a graph representation of SSA called the _SSA graph [^1]_, which is an extension of DFTs and represents the data flow for scalar variables of a procedure in SSA form. SSA graphs are a suitable representation for code generation: First, SSA graphs capture acyclic and cyclic information flow beyond basic block boundaries. Second, SSA graphs often arise naturally in modern compilers, as the intermediate code representation is usually already in SSA form. Third, output dependencies or anti-dependencies do not exist in SSA graphs.

[^1]: We consider its data-based representation here, see Chap. 14.

As even acyclic SSA graphs are generally not restricted to a tree, no dynamic programming approach can be employed for instruction code selection. To get a handle on instruction code selection for SSA graphs, below we will discuss an approach based on a problem reduction to a quadratic mathematical programming problem (PBQP). Consider the code fragment of a dot-product routine and the corresponding SSA graph shown in Fig. 19.3. The code implements a simple vector dot-product using fixed-point arithmetic. Nodes in the SSA graph represent a single operation while edges describe the flow of data that is produced at the source node and consumed at the target node. Incoming edges have an order which reflects the argument order of the operation.

The example in Fig. 19.3 has fixed-point computations that have to be expressed in the grammar. For fixed-point values most arithmetic and bit-wise operations are identical to their integer equivalents. However, some operations have different semantics, e.g., multiplying two fixed-point values in format $m.i$ results in a value with $2i$ fractional digits. The result of the multiplication has to be adjusted by a shift operation to the right (LSR). To accommodate for fixed-point values, we add the following rules to the grammar introduced in Fig. 19.2a:

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100057790.png)

In the example, the accumulation for double-precision fixed-point values (fp2) can be performed at the same cost as for the single-precision format (fp). Thus, it would be beneficial to move the necessary shift from the inner loop to the return block, performing the intermediate calculations in the extended format. Note that a tree-pattern matcher generates code at statement level, and hence the information of having values as double-precision cannot be hoisted across basic block boundaries. However, an instruction code selector that is operating on the SSA graph is able to propagate non-terminal fp2 across the $\phi$ node prior to the return and emits the code for the shift to the right in the return block.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100058221.png)

In the following, we will explain how to perform instruction code selection on SSA graphs by means of a specialized quadratic assignment problem (PBQP). First, we discuss the instruction code selection problem by employing a discrete optimization problem called a partitioned boolean quadratic problem. An extension of _patterns_ to arbitrary acyclic graph structures, which we refer to as DAG grammars, is discussed in Sect. 19.2.1.

> Figure 19.3: Instruction code selection SSA Graph for a vector dot-product in fixed-point arithmetic. “fp_” stands for unsigned short fixed-point type and “*” for pointer manipulations (like in C). The colours of the nodes indicate which basic block the operations belong to

## 19.1 Instruction Code Selection for Tree Patterns on SSA Graphs

The matching problem for SSA graphs is reduced to a discrete optimization problem called a Partitioned Boolean Quadratic Problem (PBQP). First, we will introduce the PBQP problem and then we will describe the mapping of the instruction code selection problem to PBQP.

### 19.1.1 Partitioned Boolean Quadratic Problem

Partitioned boolean quadratic programming (PBQP) is a generalized quadratic assignment problem that has proven to be effective for a wide range of applications in embedded code generation, e.g., register assignment, address mode selection, or bank selection for architectures with partitioned memory. Instead of problem-specific algorithms, these problems can be modelled in terms of generic PBQPs that are solved using a common solver library. PBQP is flexible enough to model the irregularities of embedded architectures that are hard to cope with using traditional heuristic approaches.

Consider a set of discrete variables $X=\{x_{1},\ldots,x_{n}\}$ and their finite domains $\{\mathbb{D}_{1},\ldots,\mathbb{D}_{n}\}$. A solution of PBQP is a mapping $h$ of each variable to an element in its domain, i.e., an element of $\mathbb{D}_{i}$ needs to be chosen for variable $x_{i}$. The chosen element imposes _local costs_ and _related costs_ with neighbouring variables. Hence, the quality of a solution is based on the contribution of two sets of terms.
1. For assigning variable $x_{i}$ to the element $d_{i}$ in $\mathbb{D}_{i}$. The quality of the assignment is measured by a _local cost function_$c(x_{i},d_{i})$.
2. For assigning two related variables $x_{i}$ and $x_{j}$ to the elements $d_{i}\in\mathbb{D}_{i}$ and $d_{j}\in\mathbb{D}_{j}$. We measure the quality of the assignment with a _related cost function_$C(x_{i},x_{j},d_{i},d_{j})$.

The total cost of a solution $h$ is given as
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100059248.png)
The PBQP problem seeks an assignment of variables $x_{i}$ with minimum total costs.

In the following we represent both the local cost function and the related cost function in matrix form, i.e., the related cost function $C(x_{i},x_{j},d_{i},d_{j})$ is decomposed for each pair $(x_{i},x_{j})$. The costs for the pair are represented as $|\mathbb{D}_{i}|$-by-$|\mathbb{D}_{j}|$ matrix/table $\mathscr{C}_{ij}$. A matrix element corresponds to an assignment $(d_{i},d_{j})$. Similarly, the local cost function $c(x_{i},d_{i})$ is represented by a cost vector $\overrightarrow{c_{i}}$ enumerating the costs of the elements. A PBQP problem has an underlying graph structure, expressed as graph $G=(V,E,C,c)$, which we refer to as a PBQP graph.

For each decision variable $x_{i}$ we have a corresponding node $v_{i}\in V$ in the graph, and for each cost matrix $\mathscr{C}_{l,j}$ that is not the zero matrix, we introduce an edge $e=(v_{i},\,v_{j})$. The cost functions $c$ and $C$ map nodes and edges to the original cost vectors and matrices, respectively. We will present an example later in this chapter in the context of instruction code selection.

In general, finding a solution to this minimization problem is NP-hard. However, in many practical cases, the PBQP instances are sparse, i.e., many of the cost matrices $\mathscr{C}_{l,j}$ are zero matrices and do not contribute to the overall solution. Thus, optimal or near-optimal solutions can often be found within reasonable time limits. Currently, there are two algorithmic approaches for PBQP that have been proven to be efficient in practice for instruction code selection problems, i.e., a polynomial-time heuristic algorithm and a branch-&-bound based algorithm with exponential worst-case complexity. For a certain subclass of PBQP, the algorithm produces provably optimal solutions in time $\mathcal{O}(nm^{3})$, where $n$ is the number of discrete variables and $m$ is the maximal number of elements in their domains, i.e., $m=\max\,(|\mathbb{D}_{1}|,\ldots,|\mathbb{D}_{n}|)$. For general PBQPs, however, the solution may not be optimal. To still obtain an optimal solution outside the subclass, branch-&-bound techniques can be applied.

### 19.1.2 Instruction Code Selection with PBQP

In this section, we describe the modelling of instruction code selection for SSA graphs as a PBQP problem. In the basic modelling, SSA and PBQP graphs coincide. The variables $x_{i}$ of the PBQP are decision variables reflecting the choices of applicable rules (represented by $\mathbb{D}_{i}$) for the corresponding node of $x_{i}$. The local costs reflect the costs of the rules, and the related costs reflect the costs of chain rules making rules compatible with each other. This means that the number of decision vectors and the number of cost matrices in the PBQP are determined by the number of nodes and edges in the SSA graph, respectively. The sizes of $\mathbb{D}_{i}$ depend on the number of rules in the grammar. A solution for the PBQP instance induces a complete cost-minimal cover of the SSA graph.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100107851.png)

> Figure 19.4: PBQP instance derived from the example shown in Fig. 19.2. The grammar has been normalized by introducing additional non-terminals. Highlighted elements show a cost-minimal solution

As in traditional tree-pattern matching, an ambiguous graph grammar consisting of tree patterns with associated costs and semantic actions is used. Input grammars have to be _normalized_. This means that each rule is either a so-called _base rule_ or a _chain rule_. A base rule is a production of the form $\mathtt{nt}_{0}\gets OP(\mathtt{nt}_{1},\ldots,\mathtt{nt}_{k_{p}})$ where $\mathtt{nt}_{i}$ are non-terminals and $OP$ is a terminal symbol, i.e., an operation represented by a node in the SSA graph. A chain rule is a production of the form $\mathtt{nt}_{0}\leftarrow\mathtt{nt}_{1}$, where $\mathtt{nt}_{0}$ and $\mathtt{nt}_{1}$ are non-terminals. A production rule $\mathtt{nt}\gets OP_{1}(\alpha,\,OP_{2}(\beta),\,\gamma)$) can be normalized by rewriting the rule into two production rules $\mathtt{nt}\gets OP_{1}(\alpha,\mathtt{nt}^{\prime},\gamma)$ and $\mathtt{nt}^{\prime}\gets OP_{2}(\beta)$ where $\mathtt{nt}^{\prime}$ is a new non-terminal symbol and $\alpha,\,\beta$, and $\gamma$ denote arbitrary pattern fragments. This transformation can be iteratively applied until all production rules are either chain rules or base rules. To illustrate this transformation, consider the grammar in Fig. 19.4, which is a normalized version of the tree grammar introduced in Fig. 19.2a. Temporary non-terminal symbols tl, t2, and t3 are used to decompose larger tree patterns into simple base rules. Each base rule spans across a single node in the SSA graph.

The instruction code selection problem for SSA graphs is modelled in PBQP as follows. For each node $u$ in the SSA graph, a PBQP variable $x_{u}$ is introduced. The domain of variable $x_{u}$ is determined by the subset of base rules whose terminal symbol matches the operation of the SSA node, e.g., there are three rules ($R_{4}$, $R_{5}$, $R_{6}$) that can be used to cover the shift operation SHL in our example. The last rule is the result of automatic normalization of a more complex tree pattern. The cost vector $\overrightarrow{c_{u}}=w_{u}\cdot\langle c(R_{1}),\ldots,c(R_{k_{u}})\rangle$ of variable $x_{u}$ encodes the local costs for a particular assignment where $c(R_{i})$ denotes the associated cost of base rule $R_{i}$. Weight $w_{u}$ is used as a parameter to optimize for various objectives including speed (e.g., $w_{u}$ is the expected execution frequency of the operation at node $u$) and space (e.g., the $w_{u}$ is set to one). In our example, both $R_{4}$ and $R_{5}$ have associated costs of one. Rule $R_{6}$ contributes no local costs, as we account for the full costs of a complex tree pattern at the root node. All nodes have the same weight of one, thus the cost vector for the SHL node is $\langle 1,\,1,\,0\rangle$.

An edge in the SSA graph represents data transfer between the result of an operation $u$, which is the source of the edge, and the operand $v$, which is the tail of the edge. To ensure consistency among base rules and to account for the costs of chain rules, we impose costs that are dependent on the selection of variable $x_{u}$ and variable $x_{v}$ in the form of a cost matrix $\mathcal{C}_{uv}$. An element in the matrix corresponds to the costs of selecting a specific base rule $r_{u}\in R_{u}$ of the result and a specific base rule $r_{v}\in R_{v}$ of the operand node. Assume that $r_{u}$ is $\texttt{nt}\gets OP\,(\dots)$ and $r_{v}$ is $\cdots\gets OP\,(\alpha,\texttt{nt}^{\prime},\,\beta)$ where $\texttt{nt}^{\prime}$ is the non-terminal of operand $v$ whose value is obtained from the result of node $u$. There are three possible cases:

1. If the non-terminals nt and nt' are identical, the corresponding element in matrix $\mathcal{C}_{uv}$ is zero, since the result of $u$ is compatible with the operand of node $v$.
2. If the non-terminals nt and nt' differ and there exists a rule $r:\texttt{nt}^{\prime}\leftarrow\texttt{nt}$ in the transitive closure of all chain rules, the corresponding element in $\mathcal{C}_{uv}$ has the costs of the chain rule, i.e., $w_{v}\cdot c(r)$.
3. Otherwise, the corresponding element in $\mathcal{C}_{uv}$ has infinite costs prohibiting the selection of incompatible base rules.

As an example, consider the edge from CST:2 to node SHL in Fig. 19.4. There is a single base rule $R_{1}$ with local cost $0$ and result non-terminal imm for the constant. Base rules $R_{4}$, $R_{5}$, and $R_{6}$ are applicable for the shift, the first of which expects non-terminal reg as its second argument, and rules $R_{5}$ and $R_{6}$ both expect imm. Consequently, the corresponding cost matrix accounts for the cost of converting from reg to imm at index $(1,\,1)$ and is zero otherwise.

Highlighted elements in Fig. 19.4 show a cost-minimal solution of the PBQP with cost one. A solution of the PBQP directly induces a selection of base and chain rules for the SSA graph. The execution of the semantic action rules inside a basic block follows the order of basic blocks. Special care is necessary for chain rules that correspond to data flow across basic blocks. Such chain rules may be placed inefficiently, and a placement algorithm is required for some grammars.

## 19.2 Extensions and Generalizations

### 19.2.1 Instruction Code Selection for DAG Patterns

In the previous section we have introduced an approach based on code patterns that resemble simple tree fragments. This restriction often complicates code generatorsfor modern CPUs with specialized instructions and SIMD extensions, e.g., there is no support for machine instructions with multiple results.

Consider the introductory example shown in Fig. 19.3. Many architectures have some form of auto-increment addressing modes. On such a machine, the load and the increment of both p and q can be done in a single instruction benefiting both code size and performance. However, post-increment loads cannot be modelled using a single tree-shaped pattern. Instead, it produces multiple results and spans across two non-adjacent nodes in the SSA graph, with the only restriction that their arguments have to be the same.

Similar examples can be found in most architectures, e.g., the DIVU instruction in the Motorola 68K architecture performs the division and the modulo operation for the same pair of inputs. Other examples are the RMS (read-modify-store) instructions on the IA32/AMD64 architecture, autoincrement- and decrement-addressing modes of several embedded systems architectures, the IRC instruction of the HPPA architecture, or fsincos instructions of various math libraries. Compiler writers are forced to pre- or post-process these patterns heuristically, often missing much of the optimization potential. These architecture-specific tweaks also complicate re-targeting, especially in situations where patterns are automatically derived from generic architecture descriptions.

We will now outline, through the example in Fig. 19.5, a possible problem formulation for these generalized patterns in the PBQP framework discussed so far. The code fragment contains three feasible instances of a post-increment store pattern. Assuming that $p$, $q$, and $r$ point to mutually distinct memory locations, there are no further dependencies apart from the edges shown in the SSA graph. If we select _all_ three instances of the post-increment store pattern concurrently, the cover induced by SSA edges becomes cyclic, and the code cannot be emitted. To overcome this difficulty, the idea is to express in the PBQP model a numbering of chosen nodes that reflects the existence of a topological order in the cover-avoiding cycles. PBQP has no constraints as such, but they can be simulated by imposing arbitrary high costs denoted by $\infty$ for certain combinations that do not satisfy the topological constraint.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100112792.png)


#### **Modelling**

The first step is to explicitly enumerate _instances_ of complex patterns, i.e., concrete tuples of nodes that match the terminal symbols specified in a particular production. There are three instances of the post-increment store pattern (surrounded by boxes) in the example shown in Fig. 19.5. As for tree patterns, DAG patterns are decomposed into simple base rules for the purpose of modelling, e.g., the post-increment store pattern
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100112067.png)
is decomposed into the individual pattern fragments
![](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100113196.png)
For our modelling, new variables are created for each enumerated instance of a complex production. They encode whether a particular instance is chosen or not, i.e., the domain basically consists of the elements on and off. The local costs are set to the combined costs for the particular pattern for the on state and to 0 for the off state. Furthermore, the domain of existing nodes is augmented with the base rule fragments obtained from the decomposition of complex patterns. We can safely squash all identical base rules obtained from this process into a single state. Thus, each of these new states can be seen as a proxy for the whole set of instances of (possibly different) complex productions including the node. The local costs for these proxy states are set to 0.

Continuing our example, the PBQP for the SSA graph introduced in Fig. 19.5 is shown in Fig. 19.6. In addition to the post-increment store pattern with costs three, we assume regular tree patterns for the store and the increment nodes with costs two denoted by $P_{2}$ and $P_{3}$, respectively. Rules for the VAR nodes are omitted for simplicity.

Nodes 1-6 correspond to the nodes in the SSA graph. Their domain is defined by the simple base rule with costs two and the proxy state obtained from the decomposition of the post-increment store pattern. Nodes 7, 8, and 9 correspond to the three instances identified for the post-increment store pattern. As noted before, we have to guarantee the existence of a topological order in the cover among the chosen nodes. To this end, we refine the state on such that it reflects a particular index in a concrete topological order. Matrices among these nodes account for data dependencies, e.g., consider the matrix established among nodes 7 and 8. Assuming instance 7 is on at index 2 (i.e., mapped to on${}_{2}$), the only remaining choices for instance 8 are not to use the pattern (i.e., mapped to off) or to enable it at index 3 (i.e., mapped to on${}_{3}$), as node 7 has to precede node 8.

Additional cost matrices are required to ensure that the corresponding proxy state is selected on all the variables forming a particular pattern instance (which can be modelled with combined costs of 0 or $\infty$, respectively). However, this formulation allows for the trivial solution where all of the related variables encoding the selection of a complex pattern are set to off (accounting for 0 costs) even though the artificial proxy state has been selected. We can overcome this problem by adding a large integer value $M$ to the costs for all proxy states. In exchange, we subtract these costs from the cost vector of instances. Thus, the penalties for the proxy states are effectively eliminated unless an invalid solution is selected.


Cost matrices among nodes 1-6 do not differ from the basic approach discussed before and reflect the costs of converting the non-terminal symbols involved. It should be noted that for general grammars and irreducible graphs, the heuristic solver of PBQP cannot guarantee delivering a solution that satisfies all constraints modelled in terms of $\infty$ costs. This would be an NP-complete problem. One way to work around this limitation is to include a small set of rules that cover each node individually and that can be used as a fallback rule in situations where no feasible solution has been obtained, which is similar to macro substitution techniques and ensures a correct but possibly non-optimal matching. These limitations do not apply to exact PBQP solvers such as the branch-&-bound algorithm. It is also straightforward to extend the heuristic algorithm with a backtracking scheme on RN reductions, which would of course also be exponential in the worst case.

![Fig.-19.6.svg](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310100117368.svg)

## 19.3 Concluding Remarks and Further Reading

Aggressive optimizations for the instruction code selection problem are enabled by the use of SSA graphs. The whole flow of a function is taken into account for instruction selection rather than a local scope of statements. The move from basic tree-pattern matching [1] to SSA-based DAG matching is a relatively small step as long as a PBQP library and some basic infrastructure (graph grammar translator, etc.) are provided. The complexity of the approach is hidden in the discrete optimization problem called PBQP. Free PBQP libraries are available from the web-pages of the authors and a library is implemented as part of the LLVM [186] framework.

Many aspects of the PBQP formulation presented in this chapter could not be covered in detail. The interested reader is referred to the relevant literature [108; 109] for an in-depth discussion.

As we move from acyclic linear code regions to whole-functions, it becomes less clear in which basic block the selected machine instructions should be emitted. For chain rules, the obvious choices are often non-optimal. In [254], a polynomial-time algorithm based on generic network flows is introduced that allows a more efficient placement of chain rules across basic block boundaries. This technique is orthogonal to the generalization to complex patterns.
