# Chapter 2. Properties and Flavors
Recall from the previous chapter that a procedure is in SSA form if every variable is defined only once, and every use of a variable refers to exactly one definition. Many variations, or flavours, of SSA form that satisfy these criteria can be defined, each offering its own considerations. For example, different flavours vary in terms of the number of $\phi$-functions, which affects the size of the intermediate representation; some variations are more difficult to construct, maintain, and destruct than others. This chapter explores these SSA flavours and provides insights into their relative merits in certain contexts.

## 2.1 Def-Use and Use-Def Chains

Under SSA form, each variable is defined once. Def-use chains are data structures that provide, for the single definition of a variable, the set of all its uses. In turn, a use-def chain, which under SSA consists of a single name, uniquely specifies the definition that reaches the use. As we will illustrate further in the book (see Chap. 8), def-use chains are useful for forward data-flow analysis as they provide direct connections that shorten the propagation distance between nodes that generate and use data-flow information.

Because of its single definition per variable property, SSA form simplifies def-use and use-def chains in several ways. First, SSA form simplifies def-use chainsas it combines the information as early as possible. This is illustrated by Fig. 2.1 where the def-use chain in the non-SSA program requires as many merges as there are uses of $x$, whereas the corresponding SSA form allows early and more efficient combination.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090738345.png)

Second, as it is easy to associate each variable with its single defining operation, use-def chains can be represented and maintained almost for free. As this constitutes the skeleton of the so-called SSA graph (see Chap. 14), when considering a program under SSA form, use-def chains are implicitly considered as a given. The explicit representation of use-def chains simplifies backward propagation, which favours algorithms such as dead-code elimination.

For forward propagation, since def-use chains are precisely the reverse of use-def chains, computing them is also easy; maintaining them requires minimal effort. However, even without def-use chains, some lightweight forward propagation algorithms such as copy folding[^1] are possible: Using a single pass that processes operations along a topological order traversal of a forward CFG [^2], most definitions are processed prior to their uses. When processing an operation, the use-def chain provides immediate access to the prior computed value of an argument. Conservative merging is performed when, at some loop headers, a $\phi$-function encounters an unprocessed argument. Such a lightweight propagation engine proves to be fairly efficient.

[^1]: Copy folding removes any copy $a=b$ by renaming subsequent (dominated) uses of $a$ by $b$. It is usually coupled with the SSA renaming phase.

[^2]: A forward control-flow graph is an acyclic reduction of the CFG obtained by removing back edges.
## 2.2 Minimality

SSA construction is a two-phase process: placement of $\phi$-functions, followed by renaming. The goal of the first phase is to generate code that fulfils the single reaching-definition property, as already outlined. Minimality is an additional property relating to code that has $\phi$-functions inserted, but prior to renaming; Chap. 3 describes the classical SSA construction algorithm in detail, while this section focuses primarily on describing the minimality property.

A definition $D$ of variable $v$_reaches_ a point $p$ in the CFG if there exists a path from $D$ to $p$ that does not pass through another definition of $v$. We say that a code has the _single reaching-definition property_ iff no program point can be reached by two definitions of the same variable. Under the assumption that the single reaching-definition property is fulfiled, the _minimality property_ states the minimality of the number of inserted $\phi$-functions.

This property can be characterized using the following notion of join sets. Let $n_{1}$ and $n_{2}$ be distinct basic blocks in a CFG. A basic block $n_{3}$, which may or may not be distinct from $n_{1}$ or $n_{2}$, is a _join node_ of $n_{1}$ and $n_{2}$ if there exist at least two non-empty paths, i.e., paths containing at least one CFG edge, from $n_{1}$ to $n_{3}$ and from $n_{2}$ to $n_{3}$, respectively, such that $n_{3}$ is the only basic block that occurs on both of the paths. In other words, the two paths converge at $n_{3}$ and no other CFG node. Given a set $S$ of basic blocks, $n_{3}$ is a join node of $S$ if it is the join node of at least two basic blocks in $S$. The set of join nodes of set $S$ is denoted by $\mathcal{J}(S)$.

Intuitively, a join set corresponds to the placement of $\phi$-functions. In other words, if $n_{1}$ and $n_{2}$ are basic blocks that both contain a definition of variable $v$, then we ought to instantiate $\phi$-functions for $v$ at every basic block in $\mathcal{J}(\{n_{1},n_{2}\})$. Generalizing this statement, if $D_{v}$ is the set of basic blocks containing definitions of $v$, then $\phi$-functions should be instantiated in every basic block in $\mathcal{J}(D_{v})$. As inserted $\phi$-functions are themselves definition points, some new $\phi$-functions should be inserted at $\mathcal{J}(D_{v}\cup\mathcal{J}(D_{v}))$. Actually, it turns out that $\mathcal{J}(S\cup\mathcal{J}(S))=\mathcal{J}(S)$, so the join set of the set of definition points of a variable in the original program characterizes exactly the minimum set of program points where $\phi$-functions should be inserted.

We are not aware of any optimizations that require a strict enforcement of minimality property. However, placing $\phi$-functions only at the join sets can be done easily using a simple topological traversal of the CFG as described in Chap. 4, Sect. 4.4. Classical techniques place $\phi$-functions of a variable $v$ at $\mathcal{J}(D_{v}\cup\{r\})$, with $r$ the entry node of the CFG. There are good reasons for that, as we will explain further. Finally, as explained in Chap. 3, Sect. 3.3 for reducible flow graphs, some copy-propagation engines can easily turn a non-minimal SSA code into a minimal one.

## 2.3 Strict SSA Form and Dominance Property

A procedure is defined as _strict_ if every variable is defined before it is used along every path from the entry to the exit point; otherwise, it is _non-strict_. Some languages, such as Java, impose strictness as part of the language definition; others, such as C/C++, impose no such restrictions. The code in Fig. 2.2a is non-strict as there exists a path from the entry to the use of $a$ that does not go through the definition. If this path is taken through the CFG during the execution, then $a$ will be used without ever being assigned a value. Although this may be permissible in some cases, it is usually indicative of a programmer error or poor software design.

Under SSA, because there is only a single (static) definition per variable, strictness is equivalent to the _dominance property_: Each use of a variable is dominated by its definition. In a CFG, basic block $n_{1}$_dominates_ basic block $n_{2}$ if every path in the CFG from the entry point to $n_{2}$ includes $n_{1}$. By convention, every basic block in a CFG dominates itself. Basic block $n_{1}$_strictly dominates_$n_{2}$ if $n_{1}$ dominates $n_{2}$ and $n_{1}\neq n_{2}$. We use the symbols $n_{1}$ dom $n_{2}$ and $n_{1}$ sdom $n_{2}$ to denote dominance and strict dominance, respectively.

Adding a (undefined) pseudo-definition of each variable to the entry point (root) of the procedure ensures strictness. The single reaching-definition property discussed previously mandates that each program point be reachable by exactly one definition (or pseudo-definition) of each variable. If a program point $U$ is a use of variable $v$, then the reaching definition $D$ of $v$ will dominate $U$; otherwise, there would be a path from the CFG entry node to $U$ that does not include $D$. If such a path existed, then the program would not be in strict SSA form, and a $\phi$-function would

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090740912.png)

need to be inserted somewhere in $\mathcal{J}(r,\,D)$, as in our example of Fig. 2.2b where $\perp$ represents the undefined pseudo-definition. The so-called _minimal SSA form_ is a variant of SSA form that satisfies both the minimality and dominance properties. As shall be seen in Chap. 3, minimal SSA form is obtained by placing the $\phi$-functions of variable $v$ at $\mathcal{J}(D_{v},\,r)$ using the formalism of dominance frontier. If the original procedure is non-strict, conversion to minimal SSA will create a strict SSA-based representation. Here, strictness refers solely to the SSA representation; if the input program is non-strict, conversion to and from strict SSA form cannot address errors due to uninitialized variables. To finish with, the use of an implicit pseudo-definition in the CFG entry node to enforce strictness does not change the semantics of the program by any means.

SSA with dominance property is useful for many reasons that directly originate from the structural properties of the variable live ranges. The immediate dominator or "idom" of a node $N$ is the unique node that strictly dominates $N$ but does not strictly dominate any other node that strictly dominates $N$. All nodes but the entry node have immediate dominators. A dominator tree is a tree where the children of each node are those nodes it immediately dominates. Because the immediate dominator is unique, it is a tree with the entry node as root. For each variable, its live range, i.e., the set of program points where it is live, is a sub-tree of the dominator tree. Among other consequences of this property, we can cite the ability to design a fast and efficient method to query whether a variable is live at point $q$ or an iteration-free algorithm to compute liveness sets (see Chap. 9). This property also allows efficient algorithms to test whether two variables _interfere_ (see Chap. 21). Usually, we suppose that two variables interfere if their live ranges intersect (see Sect. 2.6 for further discussions about this hypothesis). Note that in the general case, a variable is considered to be live at a program point if there exists a definition of that variable that can reach this point (reaching-definition analysis), _and_ if there exists a definition-free path to a use (upward-exposed use analysis). For strict programs, any program point from which you can reach a use without going through a definition is necessarily reachable from a definition.

Another elegant consequence is that the intersection graph of live ranges belongs to a special class of graphs called chordal graphs. Chordal graphs are significant because several problems that are NP-complete on general graphs have efficient linear-time solutions on chordal graphs, including graph colouring. Graph colouring plays an important role in register allocation, as the register assignment problem can be expressed as a colouring problem of the interference graph. In this graph, two variables are linked with an edge if they interfere, meaning they cannot be assigned the same physical location (usually, a machine register, or "colour"). The underlying chordal property highly simplifies the assignment problem otherwise considered NP-complete. In particular, a traversal of the dominator tree, i.e., a "tree scan," can colour all of the variables in the program, without requiring the explicit construction of an interference graph. The tree scan algorithm can be used for register allocation, which is discussed in greater detail in Chap. 22.

As we have already mentioned, most $\phi$-function placement algorithms are based on the notion of dominance frontier (see Chaps. 3 and 4) and consequently do provide the dominance property. As we will see in Chap. 3, this property can be broken by copy propagation: In our example of Fig. 2.2b, the argument $a_{1}$ of the copy represented by $a_{2}=\phi(a_{1},\bot)$ can be propagated and every occurrence of $a_{2}$ can be safely replaced by $a_{1}$; the now identity $\phi$-function can then be removed obtaining the initial code, that is, still SSA but not strict anymore. Making a non-strict SSA code strict is about the same complexity as SSA construction (actually we need a pruned version as described below). Still, the "strictification" usually concerns only a few variables and a restricted region of the CFG: The incremental update described in Chap. 5 will do the work with less effort.

## 2.4 Pruned SSA Form

One drawback of minimal SSA form is that it may place $\phi$-functions for a variable at a point in the control-flow graph where the variable was not actually live prior to SSA. Many program analyses and optimizations, including register allocation, are only concerned with the region of a program where a given variable is live. The primary advantage of eliminating those dead $\phi$-functions over minimal SSA form is that it has far fewer $\phi$-functions in most cases. It is possible to construct such a form while still maintaining the minimality and dominance properties otherwise. The new constraint is that every _use point_ for a given variable must be reached by exactly one definition, as opposed to all program points. Pruned SSA form satisfies these properties.

Under minimal SSA, $\phi$-functions for variable $v$ are placed at the entry points of basic blocks belonging to the set $\mathscr{J}(S, r)$. Under pruned SSA, we suppress the instantiation of a $\phi$-function at the beginning of a basic block if $v$ is not live at the entry point of that block. One possible way to do this is to perform liveness analysis prior to SSA construction, and then use the liveness information to suppress the placement of $\phi$-functions as described above; another approach is to construct minimal SSA and then remove the dead $\phi$-functions using dead-code elimination; details can be found in Chap. 3.

Figure 2.3a shows an example of minimal non-pruned SSA. The corresponding pruned SSA form would remove the dead $\phi$-function that defines $Y_{3}$ since $Y_{1}$ and $Y_{2}$ are only used in their respective definition blocks.

## 2.5 Conventional and Transformed SSA Form

In many non-SSA and graph colouring based register allocation schemes, register assignment is done at the granularity of webs. In this context, a web is the maximum unions of def-use chains that have either a use or a def in common. As an example, the code in Fig. 2.4a leads to two separate webs for variable $a$. The conversion to
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090743232.png)
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090743155.png)

minimal SSA form replaces each web of a variable $v$ in the pre-SSA program with some variable names $v_{i}$. In pruned SSA, these variable names partition the live range of the web: At every point in the procedure where the web is live, _exactly_ one variable $v_{i}$ is also live; and none of the $v_{i}$ is live at any point where the web is not.

Based on this observation, we can partition the variables in a program that has been converted to SSA form into $\phi$-equivalence classes that we will refer as $\phi$-webs. We say that $x$ and $y$ are $\phi$_-related_ to one another if they are referenced by the same $\phi$-function, i.e., if $x$ and $y$ are either parameters or defined by the $\phi$-function. The transitive closure of this relation defines an equivalence relation that partitions the variables defined locally in the procedure into equivalence classes, the $\phi$-webs. Intuitively, the $\phi$-equivalence class of a resource represents a set of resources "connected" via $\phi$-functions. For any freshly constructed SSA code, the $\phi$-webs exactly correspond to the register web of the original non-SSA code.

Conventional SSA form (C-SSA) is defined as SSA form for which each $\phi$-web is interference-free. Many program optimizations such as copy propagation may transform a procedure from conventional to a non-conventional (T-SSA for Transformed SSA) form, in which some variables belonging to the same $\phi$-web interfere with one another. Figure 3(c) shows the corresponding transformed SSA form of our previous example: Here variable $a_{1}$ interferes with variables $a_{2}$, $a_{3}$, and $a_{4}$, since it is defined at the top and used last.

Bringing back the conventional property of a T-SSA code is as "difficult" as translating out of SSA (also known as SSA "destruction," see Chap. 3). Indeed, the destruction of conventional SSA form is straightforward: Each $\phi$-web can be replaced with a single variable; all definitions and uses are renamed to use the new variable, and all $\phi$-functions involving this equivalence class are removed. SSA destruction starting from non-conventional SSA form can be performed through a conversion to conventional SSA form as an intermediate step. This conversion is achieved by inserting copy operations that dissociate interfering variables from the connecting $\phi$-functions. As those copy instructions will have to be inserted at some points to get rid of $\phi$-functions, for machine-level transformations such as register allocation or scheduling, T-SSA provides an inaccurate view of the resource usage. Another motivation for sticking to C-SSA is that the names used in the original program might help capture some properties otherwise difficult to discover. Lexical partial redundancy elimination (PRE) as described in Chap. 11 illustrates this point.

Apart from those specific examples most current compilers choose not to maintain the conventional property. Still, we should outline that, as later described in Chap. 21, checking if a given $\phi$-web is (and if necessary turning it back to) interference-free can be done in linear time (instead of the naive quadratic time algorithm) in the size of the $\phi$-web.

## 2.6 A Stronger Definition of Interference

Throughout this chapter, two variables have been said to interfere if their live ranges intersect. Intuitively, two variables with overlapping lifetimes will require two distinct storage locations; otherwise, a write to one variable will overwrite the value of the other. In particular, this definition has applied to the discussion of interference graphs and the definition of conventional SSA form, as described above.

Although it suffices for correctness, this is a fairly restrictive definition of interference, based on static considerations. Consider for instance the case when two simultaneously live variables in fact contain the same value, then it would not be a problem to put both of them in the same register. The ultimate notion of interference, which is obviously undecidable because of a reduction to the halting problem, should decide for two distinct variables whether there exists an execution for which they simultaneously hold two different values. Several "static" extensions to our simple definition are still possible, in which, under very specific conditions, variables whose live ranges overlap one another may not interfere. We present two examples.

Firstly, consider the double-diamond graph of Fig. 2.2a again, which, although non-strict, is correct as soon as the two if conditions are the same. Even if $a$ and $b$ are unique variables with overlapping live ranges, the paths along which $a$ and $b$ are respectively used and defined are mutually exclusive with one another. In this case, the program will either pass through the definition of $a$ and the use of $a$, or the definition of $b$ and the use of $b$, since all statements involved are controlled by the same condition, albeit at different conditional statements in the program. Since only one of the two paths will ever execute, it suffices to allocate a single storage location that can be used for $a$ or $b$. Thus, $a$ and $b$ do not actually interfere with one another. A simple way to refine the interference test is to check if one of the variables is live at the definition point of the other. This relaxed but correct notion of interference would not make $a$ and $b$ in Fig. 2.2a interfere while variables $a_{1}$ and $b_{1}$ of Fig. 2.2b would still interfere. This example illustrates the fact that live range splitting required here to make the code fulfil the dominance property may lead to less accurate analysis results. As far as the interference is concerned, for a SSA code with dominance property, the two notions are strictly equivalent: Two live ranges intersect iff one contains the definition of the other.

Secondly, consider two variables $u$ and $v$, whose live ranges overlap. If we can prove that $u$ and $v$ will always hold the same value at every place where both are live, then they do not actually interfere with one another. Since they always have the same value, a single storage location can be allocated for both variables, because there is only one unique value between them. Of course, this new criterion is in general undecidable. Still, a technique such as global value numbering that is straightforward to implement under SSA (see Chap. 11.5.1) can do a fairly good job, especially in the presence of a code with many variable-to-variable copies, suchas one obtained after a naive SSA destruction pass (see Chap. 3). In that case (see Chap. 21), the difference between the refined notion of interference and the non-value-based one is significant.

This refined notion of interference has significant implications if applied to SSA form. In particular, the interference graph of a procedure is no longer chordal, as any edge between two variables whose lifetimes overlap could be eliminated by this property.

## 2.7 Further Reading

The advantages of def-use and use-def chains provided almost for free under SSA are well illustrated in Chaps. 8 and 13.

The notion of minimal SSA and a corresponding efficient algorithm to compute it were introduced by Cytron et al. [90]. For this purpose they extensively develop the notion of dominance frontier of a node $n$, $\mathscr{D}\mathscr{F}(n)=\mathscr{J}(n,r)$. The fact that $\mathscr{J}^{+}(S)=\mathscr{J}(S)$ was actually discovered later, with a simple proof by Wolfe [307]. More details about the theory on (iterated) dominance frontier can be found in Chaps. 3 and 4. The post-dominance frontier, which is its symmetric notion, also known as the control dependence graph, finds many applications. Further discussions on control dependence graph can be found in Chap. 14.

Most SSA papers implicitly consider the SSA form to fulfil the dominance property. The first technique that really exploits the structural properties of the strictness is the fast SSA destruction algorithm developed by Budimlic et al. [53] and revisited in Chap. 21.

The notion of pruned SSA has been introduced by Choi, Cytron and Ferrante [67]. The example of Fig. 2.3 to illustrate the difference between pruned and non-pruned SSA has been borrowed from Cytron et al. [90]. The notions of conventional and transformed SSA were introduced by Sreedhar et al. in their seminal paper [267] for destructing SSA form. The description of the existing techniques to turn a general SSA into either a minimal, a pruned, a conventional, or a strict SSA is provided in Chap. 3.

The ultimate notion of interference was first discussed by Chaitin in his seminal paper [60] that presents the graph colouring approach for register allocation. His interference test is similar to the refined test presented in this chapter. In the context of SSA destruction, Chap. 21 addresses the issue of taking advantage of the dominance property with this refined notion of interference.
