# Chapter 5. SSA Reconstruction
Sebastian Hack

Some optimizations break the single-assignment property of the SSA form by inserting additional definitions for a single SSA value. A common example is live range splitting by inserting copy operations or inserting spill and reload code during register allocation. Other optimizations, such as loop unrolling or jump threading, might duplicate code, thus adding additional variable definitions, _and_ modify the control flow of the program. We will first mention two examples before we present algorithms to properly repair SSA.

The first example is depicted in Fig. 5.1. Our spilling pass decided to spill a part of the live range of variable $x_{0}$ in the right block in (a), resulting in the code shown in (b), where it inserted a store and a load instruction. This is indicated by assigning to the memory location $X$. The load is now a second definition of $x_{0}$, violating the SSA form that has to be reconstructed as shown in (c). This example shows that maintaining SSA also involves placing new $\phi$-functions.

Many optimizations perform such program modifications, and maintaining SSA is often one of the more complicated and error-prone parts in such optimizations, owing to the insertion of additional $\phi$-functions and the correct redirection of the uses of the variable.

Another example for such a transformation is _path duplication_ which is discussed in Chap. 20. Several popular compilers such as GCC and LLVM perform one or another variant of path duplication, for example, when _threading jumps_.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090814566.png)
##  5.1 General Considerations

In this chapter, we will discuss two algorithms. The first is an adoption of the classical dominance-frontier based algorithm. The second performs a search from the uses of the variables to the definition and places $\phi$-functions on demand at appropriate places. In contrast to the first, the second algorithm might not construct minimal SSA form in general; however, it does not need to update its internal data structures when the CFG is modified.

We consider the following scenario: The program is represented as a control-flow graph (CFG) and is in SSA form with dominance property. For the sake of simplicity, we assume that each instruction in the program only writes to a single variable. An optimization or transformation violates SSA by inserting additional definitions for an existing SSA variable, like in the examples above. The original variable and the additional definitions can be seen as a single non-SSA variable that has multiple definitions and uses. Let in the following $v$ be such a non-SSA variable.

When reconstructing SSA for $v$, we will first create fresh variables for every definition of $v$ to establish the single-assignment property. What remains is associating every use of $v$ with a suitable definition. In the algorithms, $v$.defs denotes the set of all instructions that define $v$. A use of a variable is a pair consisting of a program point (an instruction) and an integer denoting the index of the operand at this instruction.

Both algorithms presented in this chapter share the same driver routine described in Algorithm 5.1. First, we scan all definitions of $v$ so that for every basic block $b$ we have the list $b$.defs that contains all instructions in the block which define one of the variables in $v$.defs. It is best to sort this according to the schedule of the instructions in the block from back to front, making the latest definition the first in the list.

Figure 5.1: Adding a second definition as a side-effect of spillingThen, all uses of the variable $v$ are traversed to associate them with the proper definition. This can be done by using precomputed use-def chains if available or scanning all instructions in the dominance subtree of $v$'s original SSA definition. For each use, we have to differentiate whether the use is in a $\phi$-function or not. If so, the use occurs at the end of the direct predecessor block that corresponds to the position of the variable in the $\phi$'s argument list. In that case, we start looking for the reaching definition from the end of that block. Otherwise, we scan the instructions of the block backwards until we reach the first definition that is before the use (Line 14). If there is no such definition, we have to find one that reaches this block from _outside_.

We use two functions, FindDefFromTop and FindDefFromBottom that search the reaching definition, respectively, from the beginning or the end of a block. FindDefFromBottom actually just returns the last definition in the block, or call FindDefFromTop if there is none.

The two presented approaches to SSA repairing differ in the implementation of the function FindDefFromTop. The differences are described in the next two sections.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090815124.png)
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090815072.png)



## 5.2 Reconstruction Based on the Dominance Frontier

This algorithm follows the same principles as the classical SSA construction algorithm by Cytron at al. as described in Chap. 3. We first compute the iterated dominance frontier (DF${}^{+}$) of $v$. This set is a sound approximation of the set where $\phi$-functions must be placed--it might contain blocks where a $\phi$-function would be dead. Then, we search for each use $u$ the corresponding reaching definition. This search starts at the block of $u$. If that block $b$ is in the DF${}^{+}$ of $v$, a $\phi$-function needs to be placed at its entrance. This $\phi$-function becomes a new definition of $v$ and has to be inserted in $v$.defs and in $b$.defs. The operands of the newly created $\phi$-function will query their reaching definitions by recursive calls to FindDefFromBottom on direct predecessors of $b$. Because we inserted the $\phi$-function into $b$.defs _before_ searching for the arguments, no infinite recursion can occur (otherwise, it could happen, for instance, with a loop back edge).

If the block is not in the DF${}^{+}$, the search continues in the immediate dominator of the block. This is because in SSA, every use of a variable must be dominated by its definition.[^1] Therefore, the reaching definition is the same for all direct predecessors of the block, and hence for the immediate dominator of this block.

[^1]: The definition of an operand of a $\phi$-function has to dominate the corresponding direct predecessor block.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090815268.png)

## 5.3 Search-Based Reconstruction

The second algorithm presented here is adapted from an algorithm designed to construct SSA from the abstract syntax tree, but it also works well on control-flow graphs. Its major advantage over the algorithm presented in the last section is that it requires neither dominance information nor dominance frontiers. Thus it is well suited to be used in transformations that change the control-flow graph. Its disadvantage is that potentially more blocks have to be visited during the reconstruction. The principal idea is to start a search from every use to find the corresponding definition, inserting $\phi$-functions on the fly while caching the SSA variable alive at the beginning of basic blocks. As in the last section, we only consider the reconstruction for a single variable called $v$ in the following. If multiple variables have to be reconstructed, the algorithm can be applied to each variable separately.

**Search on an Acyclic CFG**

The algorithm performs a backward depth-first search in the CFG to collect the reaching definitions of $v$ in question at each block, recording the SSA variable that is alive at the beginning of a block in the "beg" field of this block. If the CFG is an acyclic graph (DAG), all predecessors of a block can be visited before the block itself is processed, as we are using a post-order traversal following edges backwards. Hence, we know all the definitions that reach a block $b$: if there is more than one definition, we need to place a $\phi$-function in $b$, otherwise it is not necessary.

**Search on a General CFG**

If the CFG has loops, there are blocks for which not all reaching definitions can be computed before we can decide whether a $\phi$-function has to be placed or not. In a loop, recursively computing the reaching definitions for a block $b$ will end up at $b$ itself. To avoid infinite recursion when we enter a block during the traversal, we first create a $\phi$-function without arguments, "pending_$\phi$." This creates a new definition $v_{\phi}$ for $v$ which is the variable alive at the beginning of this block.

When we return to $b$ after traversing the rest of the CFG, we decide whether a $\phi$-function has to be placed in $b$ by looking at the reaching definition for every direct predecessor. These reaching definitions can be either $v_{\phi}$ itself (loop in the CFG without a definition of $v$), or some other definitions of $v$. If there is only one such other definition, say $w$, then pending_$\phi$ is not necessary and we can remove it, propagating $w$ downwards instead of $v_{\phi}$. Note that in this case it will be necessary to "rewrite" all uses that referred to pending_$\phi$ to $w$. Otherwise, we keep pending_$\phi$ and fill its missing operands with the reaching definitions. In this version of function FindDefFromTop, this check is done by the function Phi-Necessary.

**Removing More Unnecessary $\phi$-Functions**

In programs with loops, it can be the case that the local optimization performed when function FindDefFromTop calls Phi-Necessary does not remove all unnecessary $\phi$-functions. This can happen in loops where $\phi$-functions can become

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090817377.png)

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090817410.png)
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090818671.png)


necessary because other $\phi$-functions are optimized away. Consider the example in Fig. 5.2. We look for a definition of $x$ from block $E$. If Algorithm FindDefFromTop considers the blocks in a unfavourable order, e.g., $E$, $D$, $C$, $B$, $A$, $D$, $C$, some unnecessary $\phi$-functions cannot be removed by Phi-Necessary, as shown in Fig. 5.2b. While the $\phi$-function in block $C$ can be eliminated by the local criterion applied by Phi-Necessary, the $\phi$-function in block $B$ remains. This is because the depth-first search carried out by FindDefFromTop will not visit block $B$ a second time. To remove the remaining $\phi$-functions, the local criterion can be iteratively applied to all placed $\phi$-functions until a fixpoint is reached. For reducible control flow, this then produces the minimal number of placed $\phi$-functions. The classical ($*$)-graph in Fig. 5.3 illustrates that this does not hold for the irreducible case. This is similar to the rules discussed in Sect. 3.3.1.

## 5.4 Further Reading

The algorithms presented in this chapter are independent of the transformation that violated SSA and can be used as a black box: For every variable for which SSA was violated, a routine is called that restores SSA. Both algorithms rely on computed def-use chains because they traverse all uses from a SSA variable to find suitable definitions; however, they differ in their prerequisites and their runtime behaviour:

The first algorithm (Choi et al. [69]) is based on the iterated dominance frontiers like the classical SSA construction algorithm by Cytron et al. [90]. Hence, it is less suited for optimizations that also change the flow of control since that would require recomputing the iterated dominance frontiers. On the other hand, by using the iterated dominance frontiers, the algorithm can find the reaching definitions quickly by scanning the dominance tree upwards. Furthermore, one could also envision applying incremental algorithms to construct the dominance tree [238; 264] and the dominance frontier [265] to account for changes in the control flow. This has not yet been done and no practical experiences have been reported so far.

The second algorithm is based on the algorithm by Braun et al. [47] which is an extension of the construction algorithm that Click describes in his thesis [75] to construct SSA from an abstract syntax tree. It does not depend on additional analysis information such as iterated dominance frontiers or the dominance tree. Thus, it is well suited for transformations that change the CFG because no information needs to be recomputed. On the other hand, it might be slower to find the reaching definitions because they are searched by a depth-first search in the CFG.

Both approaches construct _pruned_ SSA, i.e., they do not add dead $\phi$-functions.

The first approach produces minimal SSA by the very same arguments Cytron et al. [90] give. The second only guarantees minimal SSA for reducible CFGs. This follows from the iterative application of the function Phi-Necessary which implements the two simplification rules presented by Aycock and Horspool [14], who showed that their iterative application yields minimal SSA on reducible graphs. These two local rules can be extended to a non-local one which has to find strongly connected $\phi$-components that all refer to the same exterior variable. Such a non-local check also eliminates unnecessary $\phi$-functions in the irreducible case [47].