# Chapter 4 Advanced Construction Algorithms for SSA

Dibyendu Das, Upadrasta Ramakrishna, and Vugranam C. Sreedhar

The insertion of $\phi$-functions is an important step in the construction of Static Single Assignment (SSA) form. In SSA form every variable is assigned only once. At control-flow merge points $\phi$-functions are added to ensure that every use of a variable corresponds to exactly one definition. In the rest of this chapter we will present three different approaches for inserting $\phi$-functions at appropriate merge nodes. Recall that SSA construction falls into two phases of $\phi$-function insertion and variable renaming. Here we present different approaches for the first phase for minimal SSA form. We first present some properties of the DJ-graph that allow us to compute the iterated dominance frontier (DF${}^{+}$) of a given set of nodes $S$ by traversing the DJ-graph from leaves to root. $\phi$-functions can then be placed using the DF${}^{+}$ set. Based on the same properties, we then present an alternative scheme for computing DF${}^{+}$-graph based on data-flow equations, this time using a traversal of the DJ-graph from root to leaves. Finally, we describe another approach for computing the iterated dominance frontier based on the loop nesting forest.

## 4.1 Basic Algorithm

We start by recalling the basic algorithm already described in Chap. 3. The original algorithm for $\phi$-functions is based on computing the dominance frontier (DF) set for the given control-flow graph. The dominance frontier $\text{DF}(x)$ of a node $x$ is the set of all nodes $z$ such that $x$ dominates a direct predecessor of $z$, without strictly dominating $z$. For example, $\text{DF}(8)=\{6,8\}$ in Fig. 4.1. The basic algorithm for the insertion of $\phi$-functions consists in computing the iterated dominance frontier ($\text{DF}^{+}$) for a set of all definition points (or nodes where variables are defined). Let $\text{Defs}(v)$ be the set of nodes where variable $v$ is defined. Given that the dominance frontier for a set of nodes is just the union of the DF set of each node, we can compute $\text{DF}^{+}$($\text{Defs}(v)$) as a limit of the following recurrence equation (where $S$ is initially $\text{Defs}(v)$):

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090754523.png)

A $\phi$-function is then inserted at each join node in the $\text{DF}^{+}$($\text{Defs}(v)$) set.

## 4.2 Computation of $\text{DF}^{+}(S)$ Using DJ-Graphs

We now present a linear time algorithm for computing the $\text{DF}^{+}(S)$ set of a given set of nodes $S$ without the need for explicitly pre-computing the full DF set. The algorithm uses the DJ-graph (see Chap. 3, Sect. 3.1.2 and Fig. 3.3b) representation

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090754331.png)

of a CFG. The DJ-graph for our example CFG is also shown in Fig. 4.1b. Rather than explicitly computing the DF set, this algorithm uses a DJ-graph to compute the $\mathrm{DF}^{+}\left(\mathrm{Defs}(v)\right)$ on the fly.

### 4.2.1 Key Observations

Now let us try to understand how to compute the DF set for a _single node_ using the DJ-graph. Consider the DJ-graph shown in Fig. 4.1b where the depth of a node is the distance from the root in the dominator tree. The first key observation is that a DF-edge never goes down to a greater depth. To give a raw intuition of why this property holds, suppose there was a DF-edge from 8 to 7, then there would be a path from 3 to 7 through 8 without flowing through 6, which contradicts the dominance of 7 by 6.

As a consequence, to compute $\mathrm{DF}(8)$ we can simply walk down the dominator (D) tree from node 8 and from each visited node $y$, identify all join (J) edges $y \stackrel{J}{\rightarrow} z$ such that $z.\mathrm{depth}\leq 8.\mathrm{depth}$. For our example the J-edges that satisfy this condition are $10 \stackrel{J}{\rightarrow} 8$ and $9\stackrel{J}{\rightarrow} 6$. Therefore $\mathrm{DF}(8)=\{6,\,8\}$. To generalize the example, we can compute the DF of a node $x$ using the following formula (see Fig. 4.2a for an illustration):

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090757254.png)

where
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090757599.png)
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090757624.png)


Now we can extend the above idea to compute the DF${}^{+}$ for _a set of nodes_, and hence the insertion of $\phi$-functions. This algorithm does not precompute DF; given a set of initial nodes $S=\text{Defs}(v)$ for which we want to compute the relevant set of $\phi$-functions, a key observation can be made. Let $w$ be an ancestor node of a node $x$ on the dominator tree. If DF$(x)$ has already been computed before the computation of DF$(w)$, the traversal of $\mathsf{dominated}(x)$ can be avoided and DF$(x)$ directly used for the computation of DF$(w)$. This is because nodes reachable from $\mathsf{dominated}(x)$ are already in DF$(x)$. However, the converse may not be true, and therefore the order of the computation of DF is crucial.

To illustrate the key observation consider the example DJ-graph in Fig. 4.1b, and let us compute DF${}^{+}(\{3,8\})$. It is clear from the recursive definition of DF${}^{+}$ that we have to compute DF$(3)$ and DF$(8)$ as a first step. Now, suppose we start with node $3$ and compute DF$(3)$. The resulting DF set is DF$(3)=\{2\}$. Now, suppose we next compute the DF set for node $8$, and the resulting set is DF$(8)=\{6,8\}$. Notice here that we have already visited node $8$ and its subtree when visiting node $3$. We can avoid such duplicate visits by ordering the computation of DF set so that we first compute DF$(8)$ and then during the computation of DF$(3)$ we avoid visiting the subtree of node $8$ and use the result DF$(8)$ that was previously computed.

Thus, to compute DF$(w)$, where $w$ is an ancestor of $x$ in the DJ-graph, we do not need to compute it from scratch as we can re-use the information computed as part of DF$(x)$ as shown. For this, we need to compute the DF of deeper (based on depth) nodes (here, $x$), before computing the DF of a shallower node (here, $w$). The formula is as follows, with Fig. 4.2b illustrating the positions of nodes $z$ and $z^{\prime}$.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090758008.png)


### 4.2.2 Main Algorithm

In this section we present the algorithm for computing DF${}^{+}$. Let, for node $x$, $x$.depth be its depth from the root node $r$, with $r.\text{depth}=0$. To ensure that the nodes are processed according to the above observation we use a simple array of sets _OrderedBucket_, and two functions defined over this array of sets: (1) InsertNode$(n)$ that inserts the node $n$ in the set _OrderedBucket_[$n.\text{depth}$], and (2) GetDeepestNode() that returns a node from the _OrderedBucket_ with the deepest depth number.

In Algorithm 4.1, at first we insert all nodes belonging to $S$ in the _OrderedBucket_. Then the nodes are processed in a bottom-up fashion over the DJ-graph from deepest node depth to least node depth by calling Visit$(x)$. The procedure Visit$(x)$ essentially walks top-down in the DJ-graph avoiding already visited nodes. During this traversal it also peeks at destination nodes of J-edges. Whenever it notices that the depth number of the destination node of a J-edge is less than or equal to the depth number of the _current_x_, the destination node is added to the DF${}^{+}$ set (Line 4) if it is not present in $\text{DF}^{+}$ already. Notice that at Line 5 the destination node is also inserted in the _OrderedBucket_ if it was never inserted before. Finally, at Line 9 we continue to process the nodes in the subtree by visiting over the D-edges. When the algorithm terminates, the set $\text{DF}^{+}$ contains the iterated dominance frontier for the initial set $S$.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090758175.png)


In Fig. 4.3 , some of the phases of the algorithm are depicted for clarity. The OrderedBucket is populated with the nodes 1,3,4, and 7 corresponding to $S= \operatorname{Defs}(v)=\{1,3,4,7\}$. The nodes are inserted in the buckets corresponding to the depths at which they appear. Hence, node 1 which appears at depth 0 is in the 0 -th bucket, node 3 is in bucket 2 and so on. Since the nodes are processed bottom-up, the first node that is visited is node 7 . The J-edge $7 \stackrel{J}{\rightarrow} 2$ is considered, and the $\mathrm{DF}^{+}$ set is empty: the $\mathrm{DF}^{+}$ set is updated to hold node 2 according to Line 4 of the Visit procedure. In addition, InsertNode(2) is invoked and node 2 is inserted in bucket 2. The next node visited is node 4 . The J-edge $4 \stackrel{J}{\rightarrow} 5$ is considered, which results in the new $\mathrm{DF}^{+}=\{2,5\}$. The final $\mathrm{DF}^{+}$ set converges to $\{2,5,6\}$ when node 5 is visited. Subsequent visits of other nodes do not add anything to the $\mathrm{DF}^{+}$ set. An interesting case arises when node 3 is visited. Node 3 finally causes nodes 8,9 , and 10 also to be visited (Line 9 during the down traversal of the D-graph). However, when node 10 is visited, considering J-edge 1$0\lrcorner 8$ does not result in an update of the $\mathrm{DF}^{+}$ set as the depth of node 8 is deeper than that of node 3 .

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090801438.png)

## 4.3 Data-Flow Computation of DF${}^{+}$-Graph Using DJ-Graph

In this section we describe a method to iteratively compute the DF${}^{+}$ relation using a data-flow formulation. As already mentioned, the DF${}^{+}$ relation can be computed using a transitive closure of the DF-graph, which in turn can be computed from the DJ-graph. In the algorithm proposed here, explicit DF-graph construction or the transitive closure formation are not necessary. Instead, the same result can be achieved by formulating the DF${}^{+}$ relation as a data-flow problem and solving it iteratively. For several applications, this approach has been found to be a fast and effective method to construct DF${}^{+}(x)$ for each node $x$ and the corresponding $\phi$-function insertion using the DF${}^{+}(x)$ sets.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090802489.png)

The set of data-flow equations for each node $n$ in the DJ-graph can be solved iteratively using a top-down pass over the DJ-graph. To check whether multiple passes are required over the DJ-graph before a fixed point is reached for the data-flow equations, we devise an "inconsistency condition" stated as follows:
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090802134.png)

The algorithm described in the next section is directly based on the method of building up the $\mathrm{DF}^{+}(x)$ sets of the nodes as each J-edge is encountered in an iterative fashion by traversing the DJ-graph top-down. If no node is found to be _inconsistent_ after a single top-down pass, all the nodes are assumed to have reached fixed-point solutions. If any node is found to be inconsistent, multiple passes are required until a fixed-point solution is reached.

### 4.3.1 Top-Down DF${}^{+}$ Set Computation

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090803983.png)

The first and direct variant of the approach laid out above is poetically termed $\mathrm{TDMSC}$-I. This variant works by scanning the DJ-graph in a top-down fashion as shown in Line 3 of Function $\mathrm{TDMSC}$-I. All $\mathrm{DF}^{+}(x)$ sets are set to the empty set before the initial pass of $\mathrm{TDMSC}$-I. The $\mathrm{DF}^{+}(x)$ sets computed in a previous pass are carried over if a subsequent pass is required.
![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090803513.png)

The DJ-graph is visited depth by depth. During this process, for each node z encountered, if there is an incoming J-edge $y \stackrel{J}{\rightarrow} z$ as in Line 4, then a separate bottom-up pass starts at Line 8 (see Fig. 4.4a for a snapshot of the variables during algorithm execution).

This bottom-up pass traverses all nodes x such that x dominates y and $x.depth \geq y$.depth, updating the $\mathrm{DF}^{+}(x)$ values using the aforementioned data-flow equation. Line 12 is used for the inconsistency check. RequireAnotherPass is set to true only if a fixed point is not reached and the inconsistency check succeeds for any node.

There are some subtleties in the algorithm that should be noted. Line 12 of the algorithm visits incoming edges to l x only when l x is at the same depth as z, which is the current depth of inspection and the incoming edges to l x 's posterity are at a depth greater than that of node z and are unvisited yet.

Here, we will briefly walk through TDMSC-I using the DJ-graph of Fig. 4.1b (reprinted here as Fig. 4.4b). Moving top-down over the graph, the first J-edge encountered is when $z=2$, i.e., $7 \stackrel{J}{\rightarrow} 2$. As a result, a bottom-up climbing of the nodes happens, starting at node 7 and ending at node 2 and the $\mathrm{DF}^{+}$ sets of these nodes are updated so that $\mathrm{DF}^{+}(7)=\mathrm{DF}^{+}(6)=\mathrm{DF}^{+}(3)=\mathrm{DF}^{+}(2)=\{2\}$. The next J-edge to be visited can be any of $5 \stackrel{J}{\rightarrow} 6$,$9 \stackrel{\rightarrow}{\rightarrow} 6$,$6 \stackrel{J}{\rightarrow} 5$,$4 \stackrel{J}{\rightarrow} 5$, or $10^{J} \rightarrow 8$ at $\text{depth =3}$. Assume node 6 is visited first, and thus it is 5 \stackrel{J}{\rightarrow} 6, followed by $9 \stackrel{J}{\rightarrow} 6$. This results in $\mathrm{DF}^{+}(5)=\mathrm{DF}^{+}(5) \cup \mathrm{DF}^{+}(6) \cup\{6\}=\{2,6\}, \mathrm{DF}^{+}(9)= \mathrm{DF}^{+}(9) \cup \mathrm{DF}^{+}(6) \cup\{6\}=\{2,6\}$, and $\mathrm{DF}^{+}(8)=\mathrm{DF}^{+}(8) \cup \mathrm{DF}^{+}(6) \cup\{6\}=\{2,6\}$. Now, let $6^{-} \rightarrow 5$ be visited. Hence, $\operatorname{DF}^{+}(6)=\operatorname{DF}^{+}(6) \cup \mathrm{DF}^{+}(5) \cup\{5\}=\{2,5,6\}$. At this point, the inconsistency check comes into the picture for the edge $6 \stackrel{J}{\rightarrow} 5$, as $5 \stackrel{J}{\rightarrow} 6$ is another J-edge that is already visited and is an incoming edge of node 6 . Checking for $\mathrm{DF}^{+}(5) \supseteq \mathrm{DF}^{+}(6)$ fails, implying that the $\mathrm{DF}^{+}(5)$ needs to be computed again. This will be done in a succeeding pass as suggested by the RequireAnotherPass value of true. In a second iterative pass, the J-edges are visited in the same order.

Now, when $5 \stackrel{J}{\rightarrow} 6$ is visited, $\mathrm{DF}^{+}(5)=\mathrm{DF}^{+}(5) \cup \mathrm{DF}^{+}(6) \cup\{6\}=\{2,5,6\}$ as this time $\mathrm{DF}^{+}(5)=\{2,6\}$ and $\mathrm{DF}^{+}(6)=\{2,5,6\}$. On a subsequent visit of $6 \stackrel{J}{\rightarrow} 5$, $\mathrm{DF}^{+}(6)$ is also set to $\{2,5,6\}$. The inconsistency no longer appears and the algorithm proceeds to handle the edges $4 \stackrel{\lrcorner}{\rightarrow} 5$,$9 \stackrel{\lrcorner}{\rightarrow} 6$ and $10 \stackrel{b}{\rightarrow}$ which have also been visited in the earlier pass. TDMSC-I is repeatedly invoked by a different function which calls it in a loop till RequireAnotherPass is returned as false, as shown in the procedure TDMSCMain.

Once the iterated dominance frontier relation is computed for the entire CFG, inserting the \phi-functions is a straightforward application of the $\mathrm{DF}^{+}(x)$ values for a given $\operatorname{Defs}(x)$, as shown in Algorithm 4.2.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090808517.png)

## 4.4 Computing Iterated Dominance Frontier Using Loop Nesting Forests

This section illustrates the use of loop nesting forests to construct the iterated dominance frontier $\left(\mathrm{DF}^{+}\right)$of a set of vertices in a CFG. This method works with reducible as well as irreducible loops.

### 4.4.1 Loop Nesting Forest

A loop nesting forest is a data structure that represents the loops in a CFG and the containment relation between them. In the example shown in Fig. 4.5a the loops with back edges 11 \rightarrow 9 and 12 \rightarrow 2 are both reducible loops. The corresponding loop nesting forest is shown in Fig. 4.5b and consists of two loops whose header nodes are 2 and 9. The loop with header node 2 contains the loop with header node 9.
### 4.4.2 Main Algorithm

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090810614.png)
two distinct definitions reach a join point, it belongs to the $\mathrm{DF}^{+}$. Then, we take into account the back edges using the loop nesting forest: if a loop contains a definition, its header also belongs to the $\mathrm{DF}^{+}$.
A definition node $d$ "reaches" another node $u$ if there is non-empty a path in the graph from $d$ to $u$ which does not contain any redefinition. If at least two definitions reach a node $u$, then $u$ belongs to $\mathrm{DF}^{+}(S)$ where $S=\mathrm{Defs}(x)$ consists of these definition nodes. This suggests Algorithm 4.3 which works for _acyclic_ graphs. For a given $S$, we can compute $\mathrm{DF}^{+}(S)$ as follows:

* Initialize $\mathrm{DF}^{+}$ to the empty set.
* Using a topological order, compute the subset of $\mathrm{DF}^{+}(\mathrm{Defs}(x))$ that can reach a node using forward data-flow analysis.
* Add a node to $\mathrm{DF}^{+}$ if it is reachable from multiple nodes.

For Fig. 4.5, the forward CFG of the graph $G$, termed $G_{\mathit{fwd}}$, is formed by dropping the back edges $11\to 9$ and $12\to 2$. Also, $r$ is a specially designated node that is the root of the CFG. For the definitions of $x$ in nodes 4, 5, 7, and 12 in Fig. 4.5, the subsequent nodes (forward) reached by multiple definitions are 6 and 8: node 6 can be reached by any one of the two definitions in nodes 4 or 5, and node 8 by either the definition from node 7 or one of 4 or 5. Note that the back edges do not exist in the forward CFG and hence node 2 is not part of the $\mathrm{DF}^{+}$ set yet. We will see later how the $\mathrm{DF}^{+}$ set for the entire graph is computed by considering the contribution of the back edges.


Let us walk through this algorithm computing $\mathrm{DF}^{+}$ for variable $v$, i.e., $S=\{4,5,7,12\}$. The nodes in Fig. 4.5 are already numbered in topological order. Nodes 1 to 5 have only one direct predecessor, none of them being in $S$, so their _UniqueReachingDef_ stays $r$, and $\mathrm{DF}^{+}$ is still empty. For node 6, its two direct predecessors belong to $S$, hence $\textit{ReachingDefs}=\{4,5\}$, and 6 is added to $\mathrm{DF}^{+}$. Nothing changes for 7, then for 8 its direct predecessors 6 and 7 are, respectively, in $\mathrm{DF}^{+}$ and $S$: they are added to $\textit{ReachingDefs}$, and 8 is then added to $\mathrm{DF}^{+}$. Finally, for nodes 8 to 12, their _UniqueReachingDef_ will be updated to node 8, but this will no longer change $\mathrm{DF}^{+}$, which will end up being $\{6,8\}$.

### $\mathrm{DF}^{+}$ on Reducible Graphs

A reducible graph can be decomposed into an acyclic graph and a set of back edges. The contribution of back edges to the iterated dominance frontier can be identified by using the loop nesting forest. If a vertex $v$ is contained in a loop, then $\mathrm{DF}^{+}(v)$ will contain the loop header, i.e., the unique entry of the reducible loop. For any vertex $v$, let $\mathrm{HLC}(v)$ denote the set of loop headers of the loops containing $v$. Given a set of vertices $S$, it turns out that $\mathrm{DF}^{+}(S)=\mathrm{HLC}(S)\cup\mathrm{DF}^{+}_{\textit{fwd}}(S\cup \mathrm{HLC}(S))$ where $\mathrm{HLC}(S)=\bigcup_{v\in S}\mathrm{HLC}(v)$, and where $\mathrm{DF}^{+}_{\textit{fwd}}$ denote the $\mathrm{DF}^{+}$ restricted to the forward CFG $G_{\textit{fwd}}$.

Reverting back to Fig. 4.5, we see that in order to find the $\mathrm{DF}^{+}$ for the nodes defining $x$, we need to evaluate $\mathrm{DF}^{+}_{\textit{fwd}}(\{4,5,7,12\}\cup\mathrm{HLC}(\{4,5,7,12\}))$. As all these nodes are contained in a single loop with header 2, $\mathrm{HLC}(\{4,5,7,12\})=\{2\}$. Computing $\mathrm{DF}^{+}_{\textit{fwd}}(\{4,5,7,12\})$ gives us $\{6,8\}$, and finally, $\mathrm{DF}^{+}(\{4,5,7,12\})=\{2,6,8\}$.

![image.png](https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310090813258.png)

### $\text{DF}^{+}$ on Irreducible Graphs

We will now briefly explain how graphs containing irreducible loops can be handled. The insight behind the implementation is to transform the irreducible loop in such a way that an acyclic graph is created from the loop without changing the dominance properties of the nodes.

The loop in the graph of Fig. 4.6a, which is made up of nodes $v$ and $w$, is irreducible as it has two entry nodes, $v$ and $w$. We let the headers be those entry nodes. It can be transformed to the acyclic graph (c) by removing the back edges, i.e., the edges within the loop that point to the header nodes, in other words, edges $v\to w$ and $w\to v$. We create a dummy node, $\theta$, to which we connect all direct predecessors of the headers ($u$ and $s$), and that we connect to all the headers of the loop ($v$ and $w$), creating graph (d).

Following this transformation, the graph is now acyclic, and computing the $\text{DF}^{+}$ for the nodes in the original irreducible graph translates to computing $\text{DF}^{+}$ using the transformed graph to get $\text{DF}^{+}_{\not{\text{fwd}}}$ and using the loop forest of the original graph (b).

The crucial observation that allows this transformation to create an equivalent acyclic graph is the fact that the dominator tree of the transformed graph remains identical to the original graph containing an irreducible cycle.

## 4.5 Concluding Remarks and Further Reading

### Concluding Remarks

Although all these algorithms claim to be better than the original algorithm by Cytron et al., they are difficult to compare due to the unavailability of these algorithms in a common compiler framework.

In particular, while constructing the whole $\text{DF}^{+}$ set seems very costly in the classical construction algorithm, its cost is actually amortized as it will serve to

Figure 4.6: (**a**) An irreducible graph. (**b**) The loop nesting forest. (**c**) The acyclic subgraph. (**d**) Transformed graphinsert $\phi$-functions for many variables. It is, however, interesting not to pay this cost whenever we only have a few variables to consider, for instance, when repairing SSA as in the next chapter.

Note also that people have observed in production compilers that, during SSA construction, what seems to be the most expensive part is the renaming of the variables and not the insertion of $\phi$-functions.

##  Further Reading

Cytron's approach for $\phi$-function insertion involves a fully eager approach of constructing the entire DF-graph [90]. Sreedhar and Gao proposed the first algorithm for computing $\text{DF}^{+}$ sets without the need for explicitly computing the full DF set [263], producing the linear algorithm that uses DJ-graphs.

The lazy algorithm presented in this chapter that uses DJ-graph was introduced by Sreedhar and Gao and constructs DF on the fly only when a query is encountered. Pingali and Bilardi [29] suggested a middle-ground by combining both approaches. They proposed a new representation called ADT (Augmented Dominator Tree). The ADT representation can be thought of as a DJ-graph, where the DF sets are pre-computed for certain nodes called "boundary nodes" using an eager approach. For the rest of the nodes, termed "interior nodes," the DF needs to be computed on the fly as in the Sreedhar-Gao algorithm. The nodes which act as "boundary nodes" are detected in a separate pass. A factor $\beta$ is used to determine the partitioning of the nodes of a CFG into boundary or interior nodes by dividing the CFG into zones. $\beta$ is a number that represents space/query-time tradeoff. $\beta\ll 1$ denotes a fully eager approach where storage requirement for DF is maximum but query time is faster while $\beta>\!\!>1$ denotes a fully lazy approach where storage requirement is zero but query is slower.

Given the ADT of a control-flow graph, it is straightforward to modify Sreedhar and Gao's algorithm for computing $\phi$-functions in linear time. The only modification that is needed is to ensure that we need not visit all the nodes of a subtree rooted at a node $y$ when $y$ is a boundary node whose DF set is already known. This change is reflected in Line 8 of Algorithm 4.1, where a subtree rooted at $y$ is visited or not visited based on whether it is a boundary node or not.

The algorithm computing $\text{DF}^{+}$ without the explicit DF-graph is from Das and Ramakrishna [94]. For iterative $\text{DF}^{+}$ set computation, they also exhibit $\text{TMMSC-II}$, an improvement to algorithm $\text{TMMSC-I}$. This improvement is fueled by the observation that for an inconsistent node $u$, the $\text{DF}^{+}$ sets of all nodes $w$ such that $w$ dominates $u$ and $w$.depth $\geq u$.depth, can be locally corrected for some special cases. This heuristic works very well for certain classes of problems--especially for CFGs with DF-graphs having cycles consisting of a few edges. This eliminates extra passes as an inconsistent node is made consistent immediately on being detected.
